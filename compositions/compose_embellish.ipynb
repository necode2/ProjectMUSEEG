{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc806673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: brainflow in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (5.19.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from brainflow) (1.24.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from brainflow) (75.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install brainflow\n",
    "%pip install matplotlib\n",
    "from brainflow.board_shim import BoardShim, BrainFlowInputParams, BoardIds\n",
    "from brainflow.data_filter import DataFilter, FilterTypes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c259867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Compose_and_Embellish'...\n",
      "remote: Enumerating objects: 110, done.\u001b[K\n",
      "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
      "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
      "remote: Total 110 (delta 28), reused 27 (delta 16), pack-reused 62 (from 1)\u001b[K\n",
      "Receiving objects: 100% (110/110), 72.49 KiB | 1.34 MiB/s, done.\n",
      "Resolving deltas: 100% (45/45), done.\n",
      "[Errno 2] No such file or directory: '/Users/noorelbanna/Desktop/ProjectMUSEEG/ProjectB/Compose_and_Embellish'\n",
      "/Users/noorelbanna/Desktop/ProjectMUSEEG/ProjectB/compositions\n",
      "git: 'lfs' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\trefs\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/cifkao/fast-transformers.git@39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
      "  Cloning https://github.com/cifkao/fast-transformers.git (to revision 39e726864d1a279c9719d33a95868a4ea2fb5ac5) to /private/var/folders/nr/w1b31n2n1956hqwqf59y6kw40000gn/T/pip-req-build-6f6qv06w\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cifkao/fast-transformers.git /private/var/folders/nr/w1b31n2n1956hqwqf59y6kw40000gn/T/pip-req-build-6f6qv06w\n",
      "  Running command git rev-parse -q --verify 'sha^39e726864d1a279c9719d33a95868a4ea2fb5ac5'\n",
      "  Running command git fetch -q https://github.com/cifkao/fast-transformers.git 39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
      "  Running command git checkout -q 39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
      "  Resolved https://github.com/cifkao/fast-transformers.git to commit 39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from pytorch-fast-transformers==0.3.0) (1.6.0)\n",
      "Requirement already satisfied: future in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from torch->pytorch-fast-transformers==0.3.0) (1.0.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages (from torch->pytorch-fast-transformers==0.3.0) (1.24.4)\n",
      "Building wheels for collected packages: pytorch-fast-transformers\n",
      "  Building wheel for pytorch-fast-transformers (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[146 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/utils/cpp_extension.py:335: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/transformers.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/weight_mapper.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/masking.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/utils.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/causal_linear_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/full_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/improved_clustered_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/clustered_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/improved_clustered_causal_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/reformer_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/sinusoidal_positional_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/attention_layer.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/causal_relative_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/local_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/exact_topk_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/conditional_full_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention/linear_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/local_product\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/local_product/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/local_product\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/builders\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/builders/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/builders\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/builders/transformer_builders.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/builders\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/builders/attention_builders.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/builders\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/builders/base.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/builders\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/aggregate\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/aggregate/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/aggregate\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/clustering\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/clustering/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/clustering\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/transformers.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/_utils.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/hashing\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/hashing/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/hashing\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention_registry\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention_registry/registry.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention_registry\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention_registry/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention_registry\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/attention_registry/spec.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/attention_registry\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/events\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/events/event.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/events\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/events/event_dispatcher.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/events\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/events/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/events\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/events/filters.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/events\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/feature_maps\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/feature_maps/fourier_features.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/feature_maps\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/feature_maps/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/feature_maps\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/feature_maps/base.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/feature_maps\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/causal_product\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/causal_product/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/causal_product\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/sparse_product/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/sparse_product\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/clustering/hamming\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/clustering/hamming/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/clustering/hamming\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/attention/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/attention/cross_attention/full_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/attention/cross_attention/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/attention/cross_attention/attention_layer.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/attention/cross_attention/linear_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/attention/self_attention/full_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/attention/self_attention/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/attention/self_attention/attention_layer.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m copying fast_transformers/recurrent/attention/self_attention/linear_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/fast_transformers/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/aggregate\n",
      "  \u001b[31m   \u001b[0m copying tests/aggregate/test_clustered_broadcast_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/aggregate\n",
      "  \u001b[31m   \u001b[0m copying tests/aggregate/test_aggregate_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/aggregate\n",
      "  \u001b[31m   \u001b[0m copying tests/aggregate/test_clustered_aggregate_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/aggregate\n",
      "  \u001b[31m   \u001b[0m copying tests/aggregate/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/aggregate\n",
      "  \u001b[31m   \u001b[0m copying tests/aggregate/test_clustered_aggregate_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/aggregate\n",
      "  \u001b[31m   \u001b[0m copying tests/aggregate/test_aggregate_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/aggregate\n",
      "  \u001b[31m   \u001b[0m copying tests/aggregate/test_clustered_broadcast_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/aggregate\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/clustering\n",
      "  \u001b[31m   \u001b[0m copying tests/clustering/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/clustering\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/test_transformer_decoder.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/test_transformer_encoder.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/hashing\n",
      "  \u001b[31m   \u001b[0m copying tests/hashing/test_hash_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/hashing\n",
      "  \u001b[31m   \u001b[0m copying tests/hashing/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/hashing\n",
      "  \u001b[31m   \u001b[0m copying tests/hashing/test_hash_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/hashing\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/events\n",
      "  \u001b[31m   \u001b[0m copying tests/events/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/events\n",
      "  \u001b[31m   \u001b[0m copying tests/events/test_event_dispatcher.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/events\n",
      "  \u001b[31m   \u001b[0m copying tests/events/test_event_filters.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/events\n",
      "  \u001b[31m   \u001b[0m copying tests/events/test_events.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/events\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/feature_maps\n",
      "  \u001b[31m   \u001b[0m copying tests/feature_maps/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/feature_maps\n",
      "  \u001b[31m   \u001b[0m copying tests/feature_maps/test_fourier_features.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/feature_maps\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/causal_product\n",
      "  \u001b[31m   \u001b[0m copying tests/causal_product/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/causal_product\n",
      "  \u001b[31m   \u001b[0m copying tests/causal_product/test_causal_product_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/causal_product\n",
      "  \u001b[31m   \u001b[0m copying tests/causal_product/test_causal_product.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/causal_product\n",
      "  \u001b[31m   \u001b[0m copying tests/causal_product/test_causal_product_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/causal_product\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_clustered_sparse_product_backward_cpu_v2.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_sparse_product_backward_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_clustered_sparse_product_backward_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_sparse_weighted_average_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_clustered_sparse_weighted_average_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_sparse_product_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_clustered_sparse_product_cpu_v2.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_clustered_sparse_product_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_clustered_sparse_weighted_average_cpu_v2.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_sparse_product_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_clustered_sparse_weighted_average_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_sparse_weighted_average_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_clustered_sparse_product_backward_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_sparse_product_backward_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m copying tests/sparse_product/test_clustered_sparse_product_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/sparse_product\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/clustering/hamming\n",
      "  \u001b[31m   \u001b[0m copying tests/clustering/hamming/test_cluster_cpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/clustering/hamming\n",
      "  \u001b[31m   \u001b[0m copying tests/clustering/hamming/test_python_api_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/clustering/hamming\n",
      "  \u001b[31m   \u001b[0m copying tests/clustering/hamming/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/clustering/hamming\n",
      "  \u001b[31m   \u001b[0m copying tests/clustering/hamming/time_python_api_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/clustering/hamming\n",
      "  \u001b[31m   \u001b[0m copying tests/clustering/hamming/test_cluster_gpu.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/clustering/hamming\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/attention/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/attention/cross_attention/test_linear_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/attention/cross_attention/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/attention/cross_attention/test_attention_layer.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/attention/cross_attention/test_full_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/cross_attention\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/attention/self_attention/test_linear_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/attention/self_attention/__init__.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/attention/self_attention/test_attention_layer.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m copying tests/recurrent/attention/self_attention/test_full_attention.py -> build/lib.macosx-10.15-x86_64-cpython-38/tests/recurrent/attention/self_attention\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'fast_transformers.hashing.hash_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.15-x86_64-cpython-38/fast_transformers/hashing\n",
      "  \u001b[31m   \u001b[0m g++ -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/opt/anaconda3/envs/compositionenv/include -arch x86_64 -I/opt/anaconda3/envs/compositionenv/include -arch x86_64 -I/opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/include -I/opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/include/TH -I/opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/include/THC -I/opt/anaconda3/envs/compositionenv/include/python3.8 -c fast_transformers/hashing/hash_cpu.cpp -o build/temp.macosx-10.15-x86_64-cpython-38/fast_transformers/hashing/hash_cpu.o -fopenmp -ffast-math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=hash_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
      "  \u001b[31m   \u001b[0m clang++: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/g++' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pytorch-fast-transformers\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch-fast-transformers\n",
      "Failed to build pytorch-fast-transformers\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch-fast-transformers)\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Cloning into 'compose-and-embellish-pop1k7'...\n",
      "remote: Enumerating objects: 3388, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 3388 (delta 0), reused 0 (delta 0), pack-reused 3385 (from 1)\u001b[K\n",
      "Receiving objects: 100% (3388/3388), 477.23 KiB | 8.68 MiB/s, done.\n",
      "Resolving deltas: 100% (9/9), done.\n",
      "Updating files: 100% (3351/3351), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/slSeanWU/Compose_and_Embellish\n",
    "!git lfs pull\n",
    "%pip install -r requirements.txt\n",
    "%pip install git+https://github.com/cifkao/fast-transformers.git@39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
    "!git clone https://huggingface.co/slseanwu/compose-and-embellish-pop1k7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816caf43",
   "metadata": {},
   "source": [
    "# Setting up BrainFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6fad8",
   "metadata": {},
   "source": [
    "## Connecting with board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbed30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = BrainFlowInputParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2088788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-28 14:43:52.103] [board_logger] [info] incoming json: {\n",
      "    \"file\": \"\",\n",
      "    \"file_anc\": \"\",\n",
      "    \"file_aux\": \"\",\n",
      "    \"ip_address\": \"\",\n",
      "    \"ip_address_anc\": \"\",\n",
      "    \"ip_address_aux\": \"\",\n",
      "    \"ip_port\": 0,\n",
      "    \"ip_port_anc\": 0,\n",
      "    \"ip_port_aux\": 0,\n",
      "    \"ip_protocol\": 0,\n",
      "    \"mac_address\": \"\",\n",
      "    \"master_board\": -100,\n",
      "    \"other_info\": \"\",\n",
      "    \"serial_number\": \"\",\n",
      "    \"serial_port\": \"/dev/cu.usbserial-DP04VZSH\",\n",
      "    \"timeout\": 0\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error connecting to Cyton+Daisy board: UNABLE_TO_OPEN_PORT_ERROR:2 unable to prepare streaming session\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-28 14:43:52.103] [board_logger] [info] opening port /dev/cu.usbserial-DP04VZSH\n",
      "[2025-10-28 14:43:52.103] [board_logger] [error] Make sure you provided correct port name and have permissions to open it(run with sudo/admin). Also, close all other apps using this port.\n",
      "[2025-10-28 14:43:54.652] [board_logger] [info] incoming json: {\n",
      "    \"file\": \"\",\n",
      "    \"file_anc\": \"\",\n",
      "    \"file_aux\": \"\",\n",
      "    \"ip_address\": \"\",\n",
      "    \"ip_address_anc\": \"\",\n",
      "    \"ip_address_aux\": \"\",\n",
      "    \"ip_port\": 0,\n",
      "    \"ip_port_anc\": 0,\n",
      "    \"ip_port_aux\": 0,\n",
      "    \"ip_protocol\": 0,\n",
      "    \"mac_address\": \"\",\n",
      "    \"master_board\": -100,\n",
      "    \"other_info\": \"\",\n",
      "    \"serial_number\": \"\",\n",
      "    \"serial_port\": \"/dev/cu.usbserial-DP04VZSH\",\n",
      "    \"timeout\": 0\n",
      "}\n",
      "[2025-10-28 14:43:54.656] [board_logger] [info] incoming json: {\n",
      "    \"file\": \"\",\n",
      "    \"file_anc\": \"\",\n",
      "    \"file_aux\": \"\",\n",
      "    \"ip_address\": \"\",\n",
      "    \"ip_address_anc\": \"\",\n",
      "    \"ip_address_aux\": \"\",\n",
      "    \"ip_port\": 0,\n",
      "    \"ip_port_anc\": 0,\n",
      "    \"ip_port_aux\": 0,\n",
      "    \"ip_protocol\": 0,\n",
      "    \"mac_address\": \"\",\n",
      "    \"master_board\": -100,\n",
      "    \"other_info\": \"\",\n",
      "    \"serial_number\": \"\",\n",
      "    \"serial_port\": \"/dev/cu.usbserial-DP04VZSH\",\n",
      "    \"timeout\": 0\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to synthetic board.\n",
      "starting stream...\n",
      "stopping stream...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    PARAMS.serial_port = \"/dev/cu.usbserial-DP04VZSH\"\n",
    "    board_ID = BoardIds.CYTON_DAISY_BOARD\n",
    "    board = BoardShim(board_ID, PARAMS)\n",
    "    board.prepare_session()\n",
    "    print(\"Successfully connected to Cyton+Daisy board.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Cyton+Daisy board: {e}\")\n",
    "    input(\"Want to use synthetic board instead? Press Enter to continue...\")\n",
    "    board_ID = BoardIds.SYNTHETIC_BOARD\n",
    "    board = BoardShim(board_ID, PARAMS)\n",
    "    board.prepare_session()\n",
    "    print(\"Successfully connected to synthetic board.\")\n",
    "\n",
    "board.release_session()\n",
    "\n",
    "# testing sampling rate and data acquisition\n",
    "print(\"starting stream...\")\n",
    "board.prepare_session()\n",
    "board.start_stream()\n",
    "time.sleep(5)  # collect data for 5 seconds\n",
    "data = board.get_board_data()\n",
    "print(\"stopping stream...\")\n",
    "board.stop_stream()\n",
    "board.release_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949427d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(32, 1251)\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "print(data.shape)  # should be (num_channels, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a63a62",
   "metadata": {},
   "source": [
    "# Model Finetuning + Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebdb2a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nucleus parameters] t = 1.2, p = 0.97\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstage01_compose\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_plain_xl\n\u001b[1;32m      8\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference.py\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# script name\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/noorelbanna/Desktop/ProjectMUSEEG/Compose_and_Embellish/stage01_compose/config/pop1k7_finetune.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# config file\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration/stage01\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# output folder\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# number of pieces\u001b[39;00m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstage01_compose\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_vocab, dump_midi, PlainTransformer, TempoEvent\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#from stage02_embellish.inference_gpt2 import embellish_from_leadsheet\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmido\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ProjectMUSEEG/Compose_and_Embellish/stage01_compose/inference.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m max_dec_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2400\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[nucleus parameters] t = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, p = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(temp, top_p))\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# for generation w/ melody prompts\u001b[39;00m\n\u001b[1;32m     33\u001b[0m use_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/cuda/__init__.py:237\u001b[0m, in \u001b[0;36mdevice.__init__\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx \u001b[38;5;241m=\u001b[39m \u001b[43m_get_device_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/cuda/_utils.py:33\u001b[0m, in \u001b[0;36m_get_device_index\u001b[0;34m(device, optional)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m optional:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m# default cuda device index\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected a cuda device with a specified index \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     36\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor an integer, but got: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/cuda/__init__.py:384\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    383\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/cuda/__init__.py:186\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use CUDA with multiprocessing, you must use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n\u001b[0;32m--> 186\u001b[0m \u001b[43m_check_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/compositionenv/lib/python3.8/site-packages/torch/cuda/__init__.py:61\u001b[0m, in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_driver\u001b[39m():\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_isDriverSufficient\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 61\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_isDriverSufficient():\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDriverVersion() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;66;03m# found no NVIDIA driver on the system\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/noorelbanna/Desktop/ProjectMUSEEG/Compose_and_Embellish/\")\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from stage01_compose.inference_utils import generate_plain_xl\n",
    "\n",
    "sys.argv = [\n",
    "    'inference.py',  # script name\n",
    "    '/Users/noorelbanna/Desktop/ProjectMUSEEG/Compose_and_Embellish/stage01_compose/config/pop1k7_finetune.yaml',  # config file\n",
    "    'generation/stage01',  # output folder\n",
    "    '20'  # number of pieces\n",
    "]\n",
    "from stage01_compose.inference import read_vocab, dump_midi, PlainTransformer, TempoEvent\n",
    "#from stage02_embellish.inference_gpt2 import embellish_from_leadsheet\n",
    "import mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a384ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_from_notes(notes, config_path=\"stage01_compose/config/pop1k7_finetune.yaml\",\n",
    "                       output_path=\"generation/stage01/sample.mid\",\n",
    "                       temp=1.2, top_p=0.97, max_dec_len=2400, max_bars=128):\n",
    "\n",
    "    # Load config\n",
    "    config = yaml.load(open(config_path, 'r'), Loader=yaml.FullLoader)\n",
    "    event2idx, idx2event, vocab_size = read_vocab(config['data']['vocab_path'])\n",
    "\n",
    "    # Load model\n",
    "    mconf = config['model']\n",
    "    model = PlainTransformer(\n",
    "        mconf['d_word_embed'], vocab_size,\n",
    "        mconf['decoder']['n_layer'], mconf['decoder']['n_head'],\n",
    "        mconf['decoder']['d_model'], mconf['decoder']['d_ff'],\n",
    "        mconf['decoder']['tgt_len'], mconf['decoder']['tgt_len'],\n",
    "        dec_dropout=mconf['decoder']['dropout'],\n",
    "        pre_lnorm=mconf['pre_lnorm']\n",
    "    ).cuda()\n",
    "    pretrained_dict = torch.load(config['inference_param_path'], map_location='cpu')\n",
    "    model.load_state_dict(pretrained_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # Convert notes to primer format\n",
    "    primer = notes + [\"Bar_None\"]\n",
    "\n",
    "    # Generate lead sheet\n",
    "    gen_words, t_sec = generate_plain_xl(\n",
    "        model, event2idx, idx2event,\n",
    "        max_events=max_dec_len, max_bars=max_bars,\n",
    "        primer=primer, temp=temp, top_p=top_p\n",
    "    )\n",
    "\n",
    "    # Save as MIDI\n",
    "    dump_midi(gen_words, idx2event, output_path)\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ee46d",
   "metadata": {},
   "source": [
    "## Isolate EEG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_CHANNELS = BoardShim.get_eeg_channels(board_ID)\n",
    "print(f\"EEG channels: {EEG_CHANNELS}\")\n",
    "eeg_data = data[EEG_CHANNELS]\n",
    "print(f\"EEG data shape: {eeg_data.shape}\")  # should be (num_eeg_channels, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0692fc0",
   "metadata": {},
   "source": [
    "## Note Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8633ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTE_RANGE = (0, 127)  # Full MIDI note range (C1 to G9)\n",
    "\n",
    "# === OPEN MIDI OUTPUT ===\n",
    "print(\"Available MIDI outputs:\")\n",
    "print(mido.get_output_names())\n",
    "outport = mido.open_output('GarageBand Virtual In')\n",
    "print(\"connected to MIDI output: GarageBand Virtual In\")\n",
    "\n",
    "# === CONNECT TO BRAINFLOW STREAM ===\n",
    "print(\"starting stream...\")\n",
    "board.prepare_session()\n",
    "board.start_stream()\n",
    "\n",
    "# get 10 second of data to process\n",
    "board.insert_marker(\"starting base of notes\")\n",
    "time.sleep(10)  # collect data for 10 seconds\n",
    "board.insert_marker(\"ending of base notes\")\n",
    "starting_data = board.get_board_data()\n",
    "\n",
    "# Helper: map EEG voltage to MIDI note\n",
    "def voltage_to_note(v, vmin=-100, vmax=100):\n",
    "    v = np.clip(v, vmin, vmax)\n",
    "    return int(np.interp(v, [vmin, vmax], NOTE_RANGE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37764784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markers\n",
    "MARKER_CHANNEL = BoardShim.get_marker_channel(board_ID)\n",
    "print(f\"Marker channel: {MARKER_CHANNEL}\")\n",
    "marker_data = data[MARKER_CHANNEL]\n",
    "print(f\"Marker data shape: {marker_data.shape}\")\n",
    "print(\"Marker data: \", marker_data)  # print marker data to see if there are any markers, there should be none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf150098",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        # Get a sample from LSL\n",
    "        current_data = board_shim.get_current_board_data(10)\n",
    "\n",
    "        # Map EEG value to MIDI note\n",
    "        note = voltage_to_note(current_data[0][0])  # assuming channel 0\n",
    "\n",
    "        # Send MIDI note on & off\n",
    "        msg_on = mido.Message('note_on', note=note, velocity=64)\n",
    "        msg_off = mido.Message('note_off', note=note)\n",
    "\n",
    "        outport.send(msg_on)\n",
    "        print(f\"🎵 Playing note: {note} (EEG value: {eeg_value:.2f})\")\n",
    "        time.sleep(0.1)\n",
    "        outport.send(msg_off)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n Stopped by user.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e153b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_notes = []\n",
    "context_tokens = None\n",
    "\n",
    "while True:\n",
    "    # 1️⃣ Collect your new notes every 15 seconds\n",
    "    new_notes = get_new_notes()  # Your own function, returns list of (pitch, dur, time)\n",
    "    context_notes.extend(new_notes)\n",
    "\n",
    "    # Optional: keep only recent context to avoid drift\n",
    "    context_notes = context_notes[-MAX_NOTES:]\n",
    "\n",
    "    # 2️⃣ Compose: Generate lead sheet (melody + chords)\n",
    "    leadsheet_tokens = compose_from_notes(context_notes)\n",
    "\n",
    "    # 3️⃣ Embellish: Generate full piano performance\n",
    "    embellished_tokens = embellish_from_leadsheet(leadsheet_tokens, prev_context=context_tokens)\n",
    "\n",
    "    # 4️⃣ Save to MIDI\n",
    "    save_midi(embellished_tokens, \"live_output.mid\")\n",
    "\n",
    "    # Update rolling context for smooth transitions\n",
    "    context_tokens = embellished_tokens[-CONTEXT_LEN:]\n",
    "\n",
    "    # 5️⃣ Wait for next input batch\n",
    "    time.sleep(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compositionenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
